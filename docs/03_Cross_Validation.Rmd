---
title: "Cross Validation"
author: "Javier Cara"
date: "Curso 2018-19"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

El problema es que el modelo se ajusta muy bien a los datos que hemos utilizado para estimarlo, luego es razonable pensar que va a predecir bien dichos datos. Pero en la práctica, queremos el modelo para predecir datos que no conocemos. El objetivo es analizar el modelo frente a datos no conocidos.


# El método del subconjunto de validación (validation set approach)

- Dividimos en dos partes los datos (50%-50%, 40%-60%,...).
- En el **training set** estimamos el modelo.
- En el **validation set** (también conocido como **test set**) predecimos la respuesta y calculamos el Mean Squared Error (MSE) entre la variable respuesta observada y la predicha.

$$
MSE = \frac{1}{n}\sum _{i=1}^{n}{(y_i - \hat y_i)^2}
$$

```{r}
datos = read.csv("Advertising.csv")
str(datos)
```

- Dividimos los datos en training set y validation set:

```{r}
n = nrow(datos)
n_tr = 100
n_va = n - n_tr
```

```{r}
set.seed(115)

v = 1:n
pos_tr = sample(v,n_tr,replace = F) # muestreo sin reemplazamiento
pos_va = v[-pos_tr]

# dividimos los datos en training set y validation set
datos_tr = datos[pos_tr,]
datos_va = datos[pos_va,]

plot(datos_tr$TV, datos_tr$sales, pch = 19, col = "blue")
points(datos_va$TV, datos_va$sales, pch = 19, col = "red")
legend(x=0,y=25, legend=c("training","validation"), fill=c("blue","red"))
```

- En el training set estimamos el modelo:

```{r}
m1 = lm(sales ~ TV, data = datos_tr)

# error en el training set
y_tr = datos_tr$sales
y_tr_p = predict(m1,datos_tr)
```

- Error en el validation set calculamos el MSE:

```{r}
source("MSE.R")
```

```{r}
y_va = datos_va$sales
y_va_p = predict(m1,datos_va)

(mse_va = MSE(y_va,y_va_p))
```


Problemas:
- El MSE cambia en función de como se elija el training set y el validation set.
- Sólo se incluye una parte de los datos para estimar el modelo, por lo que la estimación es peor que incluyéndolos a todos.


# Leave-One-Out Cross-Validation

- Se dividen los datos en dos partes
    - training set: $\{(y_2,x_2), (y_3,x_3), \ldots, (y_n,x_n) \}$. Aquí se estima el modelo
    - test set: $(y_1,x_1)$. Calculamos el error de predicción

$$
MSE_1 = (y_1 - \hat y_1)^2
$$
- Repetimos el proceso con:
    - training set: $\{(y_1,x_1), (y_3,x_3), \ldots, (y_n,x_n) \}$. Aquí se estima el modelo
    - test set: $(y_2,x_2)$. Calculamos el error de predicción

$$
MSE_2 = (y_2 - \hat y_2)^2
$$
- Repetimos el proceso para calcular $MSE_3, MSE_4, \ldots, MSE_n$.

- el error final es la media

$$
CV = \frac{1}{n}\sum _{i=1}^{n}{MSE_i}
$$

```{r}
error_i = rep(0,n)
for (i in 1:n){
  datos_tr = datos[-i,]
  datos_va = datos[i,]
  mi = lm(sales ~ TV, data = datos_tr)
  
  yi = datos_va$sales
  yi_p = predict(mi,datos_va)
  
  error_i[i] = MSE(yi,yi_p)
}
(error_i_media = mean(error_i))
```

```{r}
plot(error_i)
lines(error_i_media*rep(1,n),col='red')
```


# k-fold Cross Validation

Se divide aleatoriamente los datos en **k** partes (o folds). Cada parte tiene n1 = n/k datos.

- Para  i = 1:k
    - la parte i constituye el test set.
    - las otras partes constituyen el train set.
    - se calcula el MSEk
- El error total es:

$$
MSE_{TOTAL} = \frac{1}{k} \sum _{i=1}^k MSE_i
$$


```{r}
# numero de folds
k_folds = 5
n = nrow(datos)
n1 = trunc(n/k_folds)
pos0 = 1:n
# lista vacia
pos = list()
set.seed(342)
for (k in 1:(k_folds-1)){
  vk = sample(1:length(pos0),n1,replace = F)
  # guardamos las posiciones del fold-k
  pos[[k]] = pos0[vk]
  # eliminamos esas posiciones
  pos0 = pos0[-vk]
}
# el ultimo puede tener mas datos que n1
pos[[k_folds]] = pos0

# forma alternativa
set.seed(342)
num_folds = k_folds
v = sample(1:n,n,replace = F)
pos1 = list()
for (k in 1:(num_folds-1)){
  pos1[[k]] = v[((k-1)*n1+1):(k*n1)]
}
pos1[[num_folds]] = v[(n-n1+1):n]

v = 1:n
error_k = rep(0,k_folds)
for (k in 1:k_folds){
  # datos de training y de validation de cada fold
  pos_va = pos[[k]]
  pos_tr = v[-pos_va]
  datos_tr = datos[pos_tr,]
  datos_va = datos[pos_va,]
  
  # estimamos el modelo
  mk = lm(sales ~ TV, data = datos_tr)
  
  # error de prediccion
  y_va = datos_va$sales
  y_va_p = predict(mk,datos_va)
  
  error_k[k] = MSE(y_va,y_va_p)
}
(errork_media = mean(error_k))
```

## Funciones para el cross-validation

```{r}
source("cross_val_pos.R")
source("cross_val_lm.R")
```

Aplicamos estas funciones a los datos:

```{r}
set.seed(342)
cross_val_lm(sales~TV,datos,k_folds)
```





